# 第一章 操作系统概述

## 功能

- 系统资源的管理者，向上层用户提供方便的接口和环境。

- 计算机硬件只认识0101二进制，但是是对用户不友好的交互接口；操作系统对上层（用户或者应用程序）暴露了友好的交互接口；上层只需要告诉操作系统需要的服务，操作系统会将具体服务转化为二进制传递给底层硬件来执行。（封装思想）

作为系统资源的管理者，OS实现了如下的功能：

- 处理机（CPU）管理
- 存储器管理
- 文件管理
- 设备管理

### 向上层提供的服务

- GUI图形化界面

- 命令接口

  - 联机命令接口 = 交互式命令接口
  - 脱机命令接口 = 批处理命令接口

- 程序接口

  - 只能通过**系统调用**来使用，通过代码来间接使用。
  - 系统调用OS为应用程序使用内核功能所提供的接口

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202212191539545.png" alt="image-20221217214508273" style="zoom: 67%;" />

- 注意库函数和系统调用的区别

  - 库函数是语言或者程序的一部分，可以运行在用户空间中；系统调用是操作系统的一部分，是内核为用户提供的程序接口，运行在内核空间中。
  - 使用到系统调用的库函数，需要上下文的转换以及状态的切换（用户态转向内核态，效率较低）

### 对硬件的扩展

对硬件扩展：将CPU、内存、硬盘、IO设备等合理组织起来，相互协调配合实现更复杂的功能。

## 四大特征

### 并发 Concurrence

#### 并发与并行概念的区别

- 并发是多个事件在同一时间间隔内发生，宏观上看是同时发生的，微观上看交替发生的，任意时间点都只进行一个事件。
- 并行是存粹的同一时间点上多个事件都在同时发生。

#### 操作系统的并发性

操作系统一开始就是伴随着“多道程序技术“而出现的，即操作系统和程序并发是一起诞生的。

- 单核CPU同一时刻只能执行一个程序，各个程序只能**并发**执行
- 多核CPU同一时刻可以执行多个程序，各个程序是**并行**执行

### 共享 Sharing

系统中的资源可以供内存中多个**并发执行**的进程共同使用。

#### 互斥共享

- 如打印机，一段时间内只允许一个进程来访问。这种资源称为**临界资源**。大部分物理设备、程序中的栈 变量 表格等属于临界资源。
- 进程A需要访问时，需要先提出请求来申请，若此时资源空闲，系统会将其分配给A使用；若A使用时又有其他进程来使用，就必须等待。A用完释放后，才允许另一进程使用。

#### 同时共享

- 这种资源允许同时有多个进程来访问。磁盘就属于这种，一些用重写码编写的文件会允许多个用户同时访问该文件。

  > 注意这种同时访问是宏观层面，在微观上可能会要求多个进程分时间片段，来交替对该资源进行访问，即分时共享。
  >
  > 注意与互斥共享的区别，互斥共享是一段时间内，只能满足一个请求；分时共享允许在一个时间段内通过时间分片让多个进程来访问。

### 虚拟 Virtual

- 时分复用：CPU的分时使用，微观上CPU在各个微小时间段内，交替为各个进程服务。
- 空分复用：存储设备，把硬盘空间变为虚拟内存。

### 异步 Async

- 并发运行的程序，会争抢使用系统资源，没抢到的就得阻塞等待；这会导致各个进程以不可预知的进度来推进，这就是异步性。
- 操作系统需要保证多次运行统一进程的结果相同。

## 发展过程

### 手工操作阶段

人工装纸带

### 批处理阶段

- 单道批处理

  - 纸带 - 磁带 - 监督程序 - 计算机
  - 监督程序控制磁带程序的执行，是操作系统的雏形
  - 程序是串行处理，CPU等IO，空闲时间太长

- 多道批处理

  - 每次往内存中读入多道程序，操作系统正式诞生，用于控制多道程序并发执行。

  - 当一道程序进入IO请求从而CPU空闲等待时，就可以转去运行另一道程序。

  - 宏观上并行：同时进入内存的多道程序都在运行，但都未运行完毕；微观上串行：多道程序轮流占用CPU，交替运行。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202212191539548.png" alt="image-20221218111241173" style="zoom:50%;" />

### 分时操作系统

为了实现人机交互+快速响应功能，出现了分时操作系统。

- 计算机以时间片的方式，轮流为各个用户服务；各个用户通过终端与计算机交互。
- 用户请求可以被及时响应；用户之间相互独立，感受不到别人的存在；用户之间相互平等。

- **但是不能优先处理紧急任务**。

### 实时操作系统

- 能**优先处理紧急任务**，具有及时性和可靠性。

## 操作系统的运行机制

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202212191539255.png" alt="image-20221218112955303" style="zoom:50%;" />

### 应用程序和内核程序

- 应用程序就是运行在操作系统之上的用户程序。
- **内核程序**是指操作系统的实现，很多内核程序就组成了操作系统内核。
- 内核简称kernel，是OS最接近硬件的部分；一个OS只要有内核就够了。

#### 内核

##### 分层设计

各项功能被分配在不同层次上

- 与硬件关联紧密的功能，如时钟管理、中断处理、设备驱动等处于最底层。
- 其次是运行频率较高的功能，如进程管理、存储器管理、设备管理等。

这个两部分构成了操作系统内核

### 特权指令和非特权指令

首先需要清楚，指令和代码是不同的。代码是指用高级语言写的程序；指令是把代码编译成CPU看得懂的一条条二进制指令。

#### 特权指令

- 比如内存清零、IO指令等，**对系统影响巨大，只允许操作系统内核来使用**，不允许用户直接使用。

**非特权指令**

- 允许用户直接使用的指令，不能访问系统中的软硬件资源，仅限于访问用户的地址空间、这是为了防止用户程序对系统的破坏。

> CPU如何区分正在运行的是内核程序还是用户程序？这就引出了内核态和用户态。

### 内核态和用户态

- 内核态 = 管态；用户态 = 目态。
- 用户自编程序运行在用户态；操作系统内核程序运行在内核态。（换句话说，内核态是在运行操作系统代码）

- CPU中有一个寄存器叫**程序状态寄存器**（PSW），其中有个二进制位，1表示内核态，0表示用户态。CPU在用户态是，只能执行非特权指令；切换状态的指令也是特权指令。

#### 状态切换

> 内核态 -> 用户态：执行一条特权指令（一般是中断返回指令），修改PSW的标志位为用户态，这意味着OS主动让出CPU使用权。
>
> 用户态 -> 内核态：由中断等引发，硬件自动完成变态过程，触发中断信号就意味着OS夺回CPU使用权。

- 除了非法指令，但凡需要OS介入的地方，都会触发中断信号，示例如下：
  - 用户程序请求系统调用
  - 用户程序产生错误指令（除数为0等）
  - 用户程序妄图执行特权指令
  - 发生一次外部中断

#### 状态切换示例

1. 刚开机，CPU为内核态，操作系统内核程序先上到CPU运行。
2. 开机完成，用户启动程序；kernel在合适的时候主动让出CPU，将PSW设为用户态；让该程序上CPU上运行。
3. 假设某个程序中有一条特权指令，CPU检测到特权指令，并发现自己在用户态。这条非法指令会引发一个**中断信号**。
4. 随后，CPU会强行变为内核态，停止当前程序，去处理一些中断相关的内核程序。（中断使得OS夺回CPU控制权）
5. 中断时间处理完后，才会再将CPU使用权交给别的应用程序。

## 中断和异常

### 中断的作用

> 中断是操作系统内核夺回CPU使用权的唯一途径。

### 中断的类型

- 内中断（异常）

  > - 中断信号来自CPU内部，与当前执行的指令有关。
  > - CPU会在执行指令时检查是否有异常发生。

  1. 故障 Fault
     - 由一些错误条件引起，如缺页故障等，可能被内核程序修复。内核程序修复故障后会将CPU使用权交还给应用程序。
  2. 自陷 Trap
     - 应用程序**主动**请求操作系统内核的服务，会执行陷入指令，该指令引发一个内中断信号。这意味着应用程序主动将CPU控制权交还给操作系统内核。
     - 系统调用就是通过陷入指令来实现的。陷入指令是在用户态执行的非特权指令。
     - 陷入指令 = trap指令 = 访管指令
  3. 终止 Abort
     - 由致命错误引起（如除数为0，非法操作码、地址越界、运算溢出等），是硬件中断；一般不会将CPU控制权再还给引发中断的应用程序，而是直接终止该程序。

- 外中断（中断）

  > - 中断信号来自CPU外部，与当前执行的指令无关。
  >
  > - 每一条指令执行结束时，CPU都会例行检查是否有外中断信号。
  
  1. 例子1：时钟中断
     - CPU外部的时钟组件，每隔一定时间向CPU发送时钟中断信号；CPU切换到内核态执行中断处理；执行完再切换到另一个程序。
  2. 例子2：IO中断，由IO设备向CPU发送中断信号。

### 中断的基本原理

- 由于中断信号不同，需要用不同的中断程序来处理。当CPU检测到中断信号时，会根据信号类型来查询**中断向量表**，以此来找到相应的中断处理程序在内存中的存放位置。
- 中断处理程序一定是内核程序，需要运行在内核态。

## 系统调用

### 作用

应用程序通过系统调用来获取操作系统内核的服务。系统调用的调用肯能发生在用户态，系统调用的执行一定是在内核态。

### 库函数与系统调用

- 用户在应用程序中，可以直接用汇编语言来请求系统调用的服务，也可以通过高级语言中的**库函数**来使用系统调用。（有些库函数需要用到系统调用，有的就不涉及）
- 高级语言通过**库函数**封装一些系统调用，以隐藏一些细节，使得程序员可以方便使用。
- 操作系统向上提供系统调用，使上层程序可以请求内核的服务。

### 系统调用的必要性

- 两个进程都需要并发的使用共享的资源，但是该资源却不能以并发的方式提供服务。（俩同学同时用打印机打印文件的例子）
- 由操作系统内核来对系统资源进行统一管理，向上提供系统调用。用户想要使用系统资源就必须通过系统调用来向操作系统内核发出请求，内核协调资源使用。

### 什么功能用到系统调用

- 涉及到共享资源的操作，必须通过系统调用来向操作系统内核提出请求，由操作系统内核代为完成，防止用户随意非法操作影响系统重要资源。

- 过程是应用程序通过陷入指令，发起系统调用，将CPU的控制权交还内核，操作系统在内核态对系统调用做处理，再切换到用户态执行应用程序。

  > 设备管理、文件管理、进程管理、进程通信、内存管理等。

### 操作系统的运行环境

- 用户通过操作系统来运行上层程序（如系统提供的命令解释程序或者用户自编程序），而上层程序的运行依赖于操作系统底层管理程序提供服务支持。

- 当需要管理程序服务时，系统通过中断机制进入内核态，运行管理程序；也可能是程序运行出现异常状况，被动需要管理程序的服务，这时通过异常处理来进入内核态。
- 管理程序运行结束后，用户程序需要继续运行，有保存现场的机制，可以返回程序断点处继续运行。

## 操作系统结构

### 组成

操作系统分为非内核部分（如GUI）和内核部分；内核运行在内核态，非内核功能运行在用户态。

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202212201953598.png" alt="image-20221220195350508" style="zoom:50%;" />

- 非内核部分

  Ubuntu、CentOS等开发团队都主要在开发非内核部分，而内核部分都用的是Linux Kernel。

- 内核部分

  - **时钟管理**

  - **中断机制**

    现代操作系统是靠中断驱动的软件。IO设备输入输出、进程管理调度、系统调用、设备驱动、文件访问等都依靠中断机制。

  - **原语**

    分层设计的OS，底层是一些可供公用调用的小程序，各自完成一定任务，比如设备驱动、CPU切换等。

    - 处于操作系统底层
    - 运行具有原子性，操作只能一气呵成
    - 运行时间较短、调用频繁

    > 以上三个功能是最贴近硬件层的功能，必须运行在内核中。

  - 系统控制的数据结构处理

    - 进程管理、存储器管理、设备管理等

    > 这些功能是对数据结构的处理，并不一定会涉及到硬件，有的操作系统不会把这些功能放在内核当中。

### 内核的分类

根据内核的设计方法不同，有不同的分类：

#### 大内核/宏内核/单内核

- 把以上所有功能都放到内核当中。
- 优点是内核中各个模块之间共享信息，并且程序调用系统功能涉及到的CPU状态切换次数较少，所以性能较高。
- 目前主流操作系统都采用的是宏内核（Windows、Linux、Android、IOS、macOS等）。

#### 微内核

- 内核中只保留与硬件关系最紧密的功能。优点是内核功能减少，方便维护。缺点是频繁切换CPU用户态和内核态，开销较大。
- 微内核与宏内核一直是同步发展的，目前微内核发展势头不错，谷歌的Fuchsia、华为鸿蒙OS、Windows NT都瞄准了微内核架构。

### 操作系统引导

操作系统也是程序，程序以数据的形式放在硬盘里，计算机有多个硬盘，硬盘又分为多个区，怎么找到操作系统？

> 操作系统引导是指计算机利用CPU运行特定程序，通过程序识别特定硬盘，识别分区，识别分区上的操作系统，最后通过程序启动操作系统。

#### 引导过程

1. 激活CPU

   激活的CPU读取ROM中的boot程序，将指令寄存器置为BIOS的第一条指令，开始执行BIOS指令。

2. 硬件自检

   BIOS启动后先硬件自检，屏幕上显示CPU、内存、硬盘等信息。

3. 加载带有操作系统的硬盘

   BIOS读取boot sequence，把控制权交给启动顺序第一位的存储设备，CPU将该存储设备引导扇区的内容加载到内存中。

4. 加载主引导记录MBR

   - 硬盘以特定的标识符来区分引导盘和非引导盘。如果发现这个盘是非引导盘，就去找下一个存储设备。直到找到引导盘的MBR
   - MBR的作用是告诉CPU去硬盘的哪个主分区找操作系统。

5. 扫描硬盘分区表，加载硬盘活动分区

   - MBR包含硬盘分区表，分区表以特定的标识符来区分活动分区和非活动分区。
   - MBR扫描硬盘分区表，找到活动分区（操作系统所在的分区），加载活动分区，将控制权交给活动分区。

6. 加载分区引导记录PBR

   - 读取活动分区的第一个扇区，这个扇区就叫PBR，其作用是寻找并激活分区根目录下，用于引导操作系统的程序（启动管理器）。

7. PBR加载启动管理器

8. 加载操作系统

# 第二章 进程管理

## 程序和进程

- 程序是存放在硬盘里面的可执行文件的集合，是静态的。
- 进程是程序的依次执行过程，是动态的。同一个程序多次执行，会对应多个进程。
- 进程是资源分配的调度的一个独立单位；是程序的一次执行过程。

> 注意这里的资源分配的含义：是指CPU、存储器等设备服务于某个进程**时间片**。

## 进程的组成 

### PCB

> - 操作系统需要对各个并发进程进行管理，所需要的信息都会放到PCB中，**进程控制块PCB**（Process Control Block）。
> - PCB常驻内存，随时存取。
>

操作怎么区分不同的进程：

- 分配唯一的PID

操作系统还需要记录：

- PID、UID（进程所属用户的ID）
- 给进程分配了多少资源（内存、IO设备、文件等）
- 进程运行情况（CPU使用时间、磁盘使用情况、网络流量使用情况等）
- 处理机相关信息（保存还原程序运行现场）

### 程序段

程序的代码（指令序列）。

### 数据段

- 运行过程中产生的各类数据。

- 程序段和数据段是给进程自己用的。

## 进程的状态与切换

### 状态

- 创建态

  - 进程正在被创建，操作系统会为其分配资源、初始化PCB
  - PCB有限，如果PCB不足，进程创建会失败；如果是内存不足，能创建，但是是会处于阻塞态等空余内存。

- 就绪态

  - 创建完成后，进入就绪态，已经具备运行条件；但是由于没有空闲CPU，暂时无法运行。
  - 系统中可能有很多个进程处于就绪态；他们在一个就绪队列中。CPU空闲时，会选择一个就绪进程上处理机运行。

- 运行态

  进程正在处理机上运行。

- 阻塞态

  - 进程运行过程中可能会等待某个时间发生（如等待系统资源分配或其他进程响应），事件发生之前进程无法继续执行，操作系统会让进程进入阻塞态，下CPU。
  - 另一个就绪态进程就会上CPU运行。
  - 等待的事件完成后，操作系统会让进程进入就绪态等待下一个时间片。

  > 进程进入阻塞态一般是进程主动请求。

- 结束态

  - 某个进程运行结束后，执行exit系统调用，请求操作系统终止该进程。
  - 操作系统回收内存空间，回收PCB。

  > 就绪态和阻塞态区别：
  >
  > - 分时操作系统中，进程的到处理机的时间非常短暂且频繁，所以进程频繁会切换到就绪态等待下一个时间片。
  > - 阻塞态，是等待其它资源过程中发生，时间相对较长，次数也会较少。

### 状态切换

- 通过**原语**来实现，保证状态切换的原子性。
- 原语的原子性是通过**关中断指令**和**开中断指令**来实现的。运行原语是CPU就不再例行检查中断信号，直到开中断指令之后才会恢复。

![image-20221221210924447](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202212212109520.png)

### 状态标识

- 进程的PCB中，会有一个变量state来表示进程的当前状态：1为创建态，2为就绪态，3为运行态
- 操作系统会将同一状态下的各个进程PCB**组织起来**，进行统一管理

### 进程的组织

#### 链接方式

![image-20221221211328104](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202212212113142.png)

#### 索引方式

简单了解

## 进程的控制

就是进程状态的切换过程，下面详细解释进程状态转换的原语

### 创建原语

- 申请空白PCB --- 为新进程分配所需资源 --- 初始化PCB --- 将PCB插入就绪队列

- 用户登录、作业调度等会创建进程（作业调度就是位于外存上还未被执行的程序，被调度出来运行）

### 撤销原语

- 从PCB集合中找到终止进程的PCB --- 立即剥夺CPU --- 终止其所有子进程 --- 该进程的资源归还给父进程或操作系统 --- 删除PCB

### 阻塞原语

- 找到进程对应的PCB --- 保护进程运行现场 --- 将PCB设为阻塞态，暂停进程运行 --- PCB插入相应的事件的等待队列

### 唤醒原语

- 在事件等待队列中找到PCB --- 设置进程为就绪态，将PCB从队列中移出 --- 将PCB插入就绪队列，等待被CPU调度

> 一般由谁引起的阻塞，就由谁唤醒。阻塞和唤醒是成对出现。

### 切换原语

- 将运行环境存到PCB中保护现场 --- PCB移到相应的队列 --- 选择另一个进程运行，更新其PCB --- 根据其PCB恢复运行环境

### 什么是运行环境

- 程序在CPU中运行时，一些临时数据会放在若干寄存器中
- 当程序运行到一半需要阻塞时，需要把必要的寄存器信息保存到PCB中，称为保存进程上下文（Context）。

### Summary

进程的控制原语，无非做如下事情：

- 更新PCB信息（修改进程状态（state）、保存/恢复运行环境）
- 将PCB插入合适的队列
- 分配/回收资源

## 进程的通信

进程拥有各自的地址空间，不同进程不可互相访问。进程之间的通信分为低级通信和高级通信两种方式。

- 低级通信只能传递状态值和整数值。
- 高级通信可以以高效率传递大量信息。

### 高级通信方法

#### 共享存储

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301012033644.png" alt="image-20230101203340519" style="zoom:50%;" />

> 两个进程通过共享存储空间互相通信，但是对共享空间的操作要具有互斥性。互斥性通过操作系统提供的**同步互斥工具（如P、V操作来实现）**

- 共享存储的分类：

  - 基于数据结构的共享

    比如，只能放一个固定长度的数组，是低级通信方式。

  - 基于存储区的共享

    操作系统只提供共享空间和同步互斥工具，里面的数据结构和交换由进程来完成。是高级通信方式。

#### 消息传递

> 如果进程之间不存在共享内存，可以使用操作系统提供的消息传递方法实现进程通信。这种方法采用格式化的信息为单位，采用发送消息和接收消息的原语来实现。

- 消息传递的分类：

  - 直接通信方式

    发送进程直接把消息发送给接收进程，并将其挂在接收进程的消息缓冲队列中；接收进程从消息缓冲队列中接收消息。

  - 间接通信方式

    发送进程将消息发送到某个中间实体上（信箱），接收进程从这个中间实体上获得消息。

#### 管道通信

> 管道：适用于连接读写进程之间的一个共享文件，本质是一个在内存中的大小固定的缓冲区。

- 特点：互斥、同步、确定通信双方的存在
- 管道只能半双工通信，实现单向传输；如果需要双向传输，需要两个管道。
- 数据以字节流的方式写入管道。管道写满时，写进程的write系统调用被阻塞，才允许读取；管道被全部读完时，读进程的read系统调用会被阻塞，才允许写入。
- 数据一旦被读出，就从管道中被抛弃，这意味着读进程最多只有一个。

## 线程

### 什么是线程

- 可以理解为轻量级进程，是CPU基本的执行单元，和程序执行流的基本单元。由线程ID、程序计数器、寄存器集合和堆栈组成。
- 资源方面：线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源。线程可以与同一进程内的其他线程共享该进程拥有的资源。
  - 引入线程后，进程只作为除CPU之外的**系统资源的分配单元**。（如内存地址空间、IO设备等，是分配给进程的）
  - 线程是处理机**调度的单位**。
- 执行方面：统一进程内的多个线程可以并发执行，但是如果线程之间有相互制约，使得线程运行具有间断性，线程也有就绪、阻塞、运行态。

### 为什么引入线程

- 传统意义上的进程是程序的一次执行，但是进程中的多个功能不可能有一个程序顺序执行所能实现的。（比如QQ里面同时视频聊天、文字聊天、发送文件）

- 为了让同一个进程可以同时执行很多事，更好的实现多道程序并发执行，引入了线程来增加并发度，减小程序执行的付出的时空开销。
  - 传统的进程间并发，切换进程的运行环境，系统的开销很大；同一进程内的线程间并发，不需要切换进程运行环境，系统开销小。

### 线程与进程的比较

- 调度
  - 进程是拥有资源的基本单位，线程是CPU调度的基本单位。
- 拥有资源
  - 进程拥有资源；线程不拥有系统资源，但是可以访问隶属进程的资源。
- 并发性
  - 皆可并发，提高系统并发度。
- 系统开销
  - 进程切换需要保存前一个进程的CPU环境，切换新调度的进程的CPU环境，开销较大；而线程切换只需要保存设置少量寄存器的内容，开销很小。
- 地址空间和其他资源
  - 进程之间地址空间相互独立，同一进程各线程之间共享进程资源。
- 通信方面
  - 进程之间的通信直接通过共享的进程内存空间来实现，无需操作系统的干预。

### 线程的实现方式

#### 用户级线程

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301041339608.png" alt="image-20230104133917514" style="zoom:50%;" />

- 早期操作系统还不支持线程，当时的线程是由程序员在应用代码中自己实现的线程库。
- 线程的管理工作由应用完成，线程切换不需要CPU变态；操作系统只认识进程，而不认识线程。这种情况下，进程仍是CPU调度的基本单位。

> 优点是线程切换开销较小；缺点是多线程并不能在多核处理机上并发运行，并且当一个用户线程被阻塞后，整个进程都会被阻塞，并发度不高。

- 为啥当一个用户线程被阻塞，整个进程都会被阻塞？

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301041356931.png" alt="image-20230104135620870" style="zoom: 80%;" />

​	如示例，线程库实际上是循环中的三个条件，当一个条件分支阻塞住了，整个循环（即进程也就阻塞住了）

#### 内核级线程

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301041359718.png" alt="image-20230104135956672" style="zoom:80%;" />

- 内核级线程管理工作是由操作系统内核完成；线程调度、切换都应由内核实现，要在内核态才能完成。

- 操作系统会为每个线程建立TCB（线程控制块），通过管理TCB来实现线程管理。此情况下，线程是CPU调度的基本单位。

  > 优点是一个线程被阻塞后，其他线程还能继续执行，并发度高；多线程可以在多核处理机上并发执行。

#### 区别与联系

- 用户级线程可以理解为“代码逻辑”的载体；内核级线程可以理解为“运行机会”的载体。
- 一段代码逻辑，只有获得了运行机会，才能被CPU执行；而**内核级线程才是CPU分配的单位**。（比如上述进程有3个内核级线程，那么CPU最多分配3个核心给这个进程）
- 内核级线程中可以运行任意一个有映射关系的用户级线程代码，只有所有内核级线程中的代码逻辑都阻塞时，这个进程才会阻塞。

### 多线程模型

把用户级线程和内核级线程结合起来就可以实现多种多线程模型。程序员要保证线程之间不发生冲突

#### 一对一模型

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301041443126.png" alt="image-20230104144345070" style="zoom:80%;" />

- 一个用户级线程映射到一个内核级线程；同一进程拥有多个内核级线程。
- 并发性好，但是线程切换导致的CPU变态会有较大的开销。

#### 多对一模型

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301041457138.png" alt="image-20230104145711081" style="zoom:80%;" />

- 多个用户级线程映射到一个内核级线程。且一个进程只被分配到一个内核级线程。

- 线程切换在用户态即可完成，线程管理的效率高、开销小；缺点与用户级线程一样：当一个用户级线程被阻塞后，整个进程都被阻塞；并且并发度不高。

  > 注意：操作系统只看得见内核级线程，只有**内核级线程**才是处理机分配的单位。

#### 多对多模型

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301041512132.png" alt="image-20230104151237070" style="zoom:80%;" />

- n个用户级线程对应m个内核级线程（n>=m），既能克服多对一模型的并发度低的缺点，又能克服一对一模型的切换线程开销高的缺点。

## 处理机调度

### 调度

- 任务多，资源有限的情况下，没法同时处理所有任务；就需要有某种规则来决定这些任务执行的顺序。这就是调度来研究的问题。

### 作业

- 作业是指一个具体的执行任务
- 用户向系统提交一个作业，即用户让系统启动一个程序（处理一项具体任务）。
- 作业首先会在外存中等待被系统调度；调度后将作业调入内存，建立起进程，等待被CPU调度。

### 处理机调度的三个层次

#### 高级调度

> 背景：由于内存有限，有时无法将用户提交的全部作业都放入内存。

- 按照一定的原则从外存的作业的后备队列中挑选一个作业存入内存，创建进程。**每个作业只调入一次，调出一次**；调入的时候建立PCB，调出时撤销。

#### 低级调度/进程调度/处理机调度

> 背景：就绪队列中有多个进程，按照某种策略在其中选取一个进程，将处理机分配。

- 进程调度是操作系统中最基本的一种调度。

- 频率很高，几十毫秒一次。高频的进程调度才能让各个进程轮流上处理机运行，实现宏观上的并发执行。

#### 中级调度/内存调度

> 背景：内存不够时，将某些进程的数据移出内存，存入外存，等内存空闲时或进程需要运行时，再重新调入内存。

- 暂时掉到外存的进程状态为**挂起状态**；处于挂起状态的进程的PCB被组织到**挂起队列**中。
- 中级调度就是按照某种策略决定将哪一个挂起状态的进程重新调回内存。
- 一个进程可能会被多次调入调出内存，中级调度的发生频率要高于高级调度。

#### 三种调度对比

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301042127042.png" alt="image-20230104212727980" style="zoom:80%;" />

### 进程七状态模型

引入挂起态后，进程的状态更新为七状态模型：

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301042122248.png" alt="image-20230104212257161" style="zoom: 80%;" />

## 进程调度

从就绪队列中选中一个要运行的进程；让现在的进程让出处理机，由另一个进程上处理机运行。

### 时机

#### 需要进行进程切换

- 当前进程主动放弃处理机
  - 进程正常终止
  - 进程运行异常而终止
  - 进程主动请求阻塞，如等待IO
- 当前进程被动放弃处理机
  - 分给进程的时间片用完
  - 有更紧急的事情处理（如IO中断）
  - 有更高优先级的进程进入队列

#### 不能进行进程切换

- 处理中断时。处理机处理中断过程复杂，与硬件密切相关，很难做到处理中断同时处理进程切换。
- 进程在访问**操作系统内核程序临界区**中。

- 在原子操作中（原语）。原子操作要一气呵成，不能中断。

#### 临界资源

- **临界资源**：虽然进程可以共享系统中的各种资源，但其中许多资源一次只能为一个进程所用，我们将一个时间段内只允许一个进程使用的资源。各进程需要互斥地访问的资源叫做临界资源。

- **普通临界资源**：如打印机，摄像头等，进程访问这些资源的时候，运行速度很慢，并且会阻塞其他请求这一资源的进程，直到本进程结束，才在等待队列中唤醒一个等待的进程。

- **临界资源四个部分**：进入区（检查并上锁）、临界区（进程访问临界资源资源的那段代码）、退出区（标志清除）和剩余区。

- **内核程序临界区**：

  - 内核数据结构，比如进程的就绪队列。

  - 进程进入内核临界区后，进程需要**独占式访问**，理论上必须给该内核临界资源加锁，以防止其他进程入内。

  - 进程访问内核程序临界区要快，否则会影响内核的管理工作；解锁前不应切换到其他进程，以加快临界区的释放。
  - 并且进程访问临界区的时候，不能发生进程调度与切换。

### 进程调度方式

#### 非剥夺

- 只允许进程主动放弃处理机。

- 进程运行中，如果有更紧急的任务到达，当前进程依然会继续使用处理机，直到该进程终止或者主动进入阻塞态。

  > 系统开销小，但是无法及时处理紧急任务。仅适用于早期的批处理系统。

#### 剥夺/抢占

- 进程运行中，如果有更紧急的任务到达，处理机立即暂停正执行的进程，将处理机分配给更紧急的进程。

  > 可以优先处理更紧急的进程，也能实现各进程按时间片轮流执行（通过时钟中断）。适用于分时操作系统。

### 切换与过程

进程切换的过程简单讲完成了两件事：

1. 对原来的进程进行保存现场
2. 对新的进程进行运行现场的恢复

> 如：程序计数器、程序状态字、各种数据寄存器等处理及现场信息。
>
> 这些信息一般保存在PCB中。保存现场就是保存到PCB中；恢复现场也从PCB中恢复。

**注意：进程切换也是有代价的，如果过于频繁的切换进程，真正用于进程执行的时间会减少，反而会降低系统效率。**

## 调度算法的评价指标

### CPU利用率

- 早期CPU造价昂贵，希望CPU尽可能多的工作。
- CPU利用率：CPU**忙碌的时间**占**总时间**的比例。

### 系统吞吐量

- 系统吞吐量 = 总共完成了多少道作业 / 总共花了多少时间

### 周转时间

- 从 作业被提交给系统 到 作业完成 所花费的时间

> 包含：作业在外存后备队列上等待被调度（高级调度） - 进程在就绪队列上等待被调度（低级调度） - 进程在CPU上执行 - 进程在阻塞态上等待IO设备

#### 带权周转时间

- 周转时间包含了 等 + 运行 的时间；周转总时间相同的情况下，肯定是等的少，运行的多，用户满意度才高。

- 带权周转时间：**作业总周转时间 / 作业实际上CPU运行的时间** （肯定>1，越小越好）

### 等待时间

- 对于作业而言，等待时间 = 作业在外存等待被调度时间 + 建立进程后等待上CPU的时间

- 对于进程而言，等待时间是进程建立后，等待被服务的时间之和。（进程等待IO设备的时间，IO设备也为进程服务，不算做等待时间）

### 响应时间

- 用户提交请求，到首次获得系统响应的时间。

## 调度算法

### 先来先服务（FCFS）

1. 算法思想

   - 从公平角度考虑

2. 算法规则

   - 按照作业/进程到达的先后顺序进行服务

3. 用于作业/进程调度

   - 用于作业调度，考虑的是哪个作业先到达后备队列
   - 用于进程调度时，考虑哪个进程先到达就绪队列

4. 是否可抢占

   - 非抢占式

5. 优缺点

   - 优点：公平、算法简单。
   - 缺点：排在长作业之后的短作业，带权周转时间很大，对短作业的用户体验不好。（排队买奶茶，你买一杯，但是前面一个人买20杯，你就要被迫等很长时间）；对长作业有利，对短作业不利。

6. 是否会导致饥饿

   > 饥饿就是某个作业/进程长期得不到服务

   - 不会导致饥饿

### 短作业/进程优先（SFJ/SPF）

1. 算法思想
   - 追求最少的平均等待时间，最少的平均周转时间和平均带权周转时间

2. 算法规则
   - 每次调度，选择当前**已到达**并且**运行时间最短**的作业/进程。

3. 用于作业/进程调度

   都可以

4. 是否可抢占
   - 默认是非抢占式的版本
   - 也有抢占式的版本：**最短剩余时间优先算法（SRTN）**。
     - 每当有进程加入，引起就绪队列改变时，就要调度。if 新到达的进程剩余运行时间 < 当前进程剩余运行时间，then 新进程抢占处理机 and 当前进程返回就绪队列。
     - 抢占式的版本，比非抢占式的，平均周转时间会更低。

5. 优缺点
   - 优点：最短的平均等待时间和平均周转时间
   - 缺点：对短作业有利，对长作业不利；而且作业/进程的运行时间是由用户提供的，并不一定真实。

6. 是否会导致饥饿
   - 如果源源不断的有短作业/进程到来，可能使长作业/进程长时间得不到服务，产生饥饿。

### 高响应比优先（HRRN）

1. 算法思想
   - 综合考虑作业/进程的等待时间和要求服务的时间

2. 算法规则
   - 每次调度的时候，先计算各个作业/进程的响应比，选择响应比最高的作业/进程为其服务
   - 响应比 = （等待时间 + 要求服务时间）/ 要求服务时间

3. 用于作业/进程调度

   都可以

4. 是否可抢占
   - 非抢占式的，只有作业or进程主动放弃处理机时，才需要调度，才需要计算响应比。

5. 优缺点
   - 优点：等待时间相同时，要求服务时间短的优先（SJF的优点）；要求服务时间相同时，等待时间长的优先（FCFS的优点）。
   - 缺点：

6. 是否会导致饥饿
   - 不会导致饥饿。

> 以上三种算法，只考虑了平均周转时间、平均等待时间等系统整体性能指标，并未考虑响应时间，也不区分任务紧急程度。只适用于早期的批处理操作系统。
>
> 所以对用户而言，交互性很糟糕。
>
> 以下的算法适用于分时和实时操作系统，更关注进程的响应时间。

### 时间片轮转（RR）

1. 算法思想
   - 公平、轮流的为各个进程服务；每个进程在一定时间间隔内都可以得到服务。
2. 算法规则
   - 按照各个进程到达就绪队列的顺序，轮流让各个进程执行一段时间片；没执行完也要剥夺处理机，将进程重新放回就绪队列尾部排队。
3. 用于作业/进程调度
   - 只用于进程调度。（只有作业从外存调入内存建立进程后，才会被分配处理及时间片）
4. 是否可抢占
   - 抢占式算法，由时钟装置发出的时钟中断来通知CPU时间片已满。
5. 优缺点
   - 优点：公平，响应快。
   - 缺点：
     - 如果时间片太大，每个进程都可以在时间片内完成；那么时间片轮转算法会退化为先来先服务算法，增大进程的响应时间。所以时间片不能太大。如果时间片过小的话，进程切换太过频繁，会导致系统消耗变大，效率降低。所以时间片也不能过小。（一般来说，切换进程所带来的开销占比不超过1%。）
     - 未对任务的紧急程度作区分。
6. 是否会导致饥饿
   - 不会

### 优先级调度

1. 算法思想

   - 实时操作系统的出现，越来越多应用场景需要根据任务的紧急程度来决定处理顺序。

2. 算法规则

   - 每个作业/进程有各自的优先级，调度时选择优先级最高的作业/进程。
   - 优先级也分为**静态优先级**和**动态优先级**
     - 动态优先级是指优先级可以动态变化：就绪队列中的等待时间长，就提高优先级；进程占用处理机的时间长，就降低优先级；进程频繁进行IO操作，就提升优先级。

   > 通常情况：系统进程优先级高于用户进程；前台进程优先级高于后台进程；操作系统更偏好于IO型繁忙进程先运行。
   >
   > （IO繁忙型进程先运行，IO设备就会早投入工作，与CPU并行工作，资源利用率就高。与IO繁忙型进程对应的是：计算型进程，不会用到IO设备）

3. 用于作业/进程调度

   - 可用于作业调度、进程调度、IO调度等场景

4. 是否可抢占

   - 有非抢占式的版本：进程主动放弃处理机时才会发生调度。
   - 也有抢占式的版本：只要进程结束或者就绪队列发生变化，就去检查是否需要进行抢占调度。

5. 优缺点

   - 优点：灵活应对各种作业进程的偏好程度，适用于实时操作系统
   - 缺点：会导致饥饿。

6. 是否会导致饥饿

   - 会。如果源源不断的有高优先级的进程到来，低优先级的进程可能会饥饿。

### 多级反馈队列

1. 算法思想

   - 对其他调度算法的折中权衡。

2. 算法规则

   - 设置多级继续队列，各级就绪队列优先级从高到低，时间片从小到大。

     <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301101436902.png" alt="image-20230110143607771" style="zoom:67%;" />

   - 新进程到达时先进入1级队列，按FCFS原则排队等待被分配时间片；

     - 若时间片用完进程还没结束，则进入下一级队列队尾。
     - 如果已经是最后一级队列，那就直接放到该队列队尾。
     - 如果进程被抢占剥夺时间片，则会放回到本队列队尾。

   - 只有第k级队列为空时，才会为第k+1级队列进程分配时间片。

3. 用于作业/进程调度

   - 用于进程调度

4. 是否可抢占

   - 是抢占式的算法。在k级队列进程运行过程中，若更上级的队列(1~k-1)中进入了一个新进程，则由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，原来的进程放回k级队列队尾。

5. 优缺点

   - 优点：
     - 对各类型进程相对公平（FCFS的优点）；
     - 每个新到达的进程都可以很快得到响应（RR的优点）；
     - 短进程较少时间就可以完成（SPF）；
     - 不必实现估计进程的运行时间，避免用户作假。可以灵活调整对各类进程的偏好程度（优先级调度的优点）。（比如可以将因为IO阻塞的进程被唤醒时，重新放回原队列，这样IO型进程就会保持高优先级。）
   - 缺点

6. 是否会导致饥饿

   - 可能会。如果源源不断的高优先级进程进来，低优先级进程可能会饥饿。

> 以上三种算法注重于响应时间、公平性等指标，更适合于实时操作系统。
>
> 比如UNIX系统使用的就是多级反馈队列调度算法。

## 进程同步与互斥

### 进程同步

- 进程具有异步性的特征，各个并发执行的进程是以各自独立的、不可预知的速度向前推进。我们不可预知进程执行的先后顺序，但是有些情况下必须让进程以固定的先后顺序来执行。
- 同步，亦称为直接制约关系，为完成某种任务，而建立的多个进程，相互有**合作关系**。这些进程由于需要在某些位置上协调它们的工作次序而产生的制约关系。

### 进程互斥

- 并发进程之间，不可避免的需要共享一些系统资源（内存、打印机、摄像头等设备），有一些系统资源属于是临界资源，需要互斥访问。

  （临界资源举例：一些物理设备如摄像头、打印机等；变量、数据、内存缓冲区等）

#### 临界资源组成

```C++
do{
    entry section; //进入区，负责检查是否可以进入临界区，若可以进入，则设置成“正在访问临界资源”，即“上锁”，阻止其他进程访问。
    critical section; //临界区，访问临界资源的那段代码
    exit section; //负责解锁
    remainder section; //作其他处理。
} while (true)
```

- 临界区是进程中访问临界资源的代码段
- 进入区和退出区是负责进程互斥的代码段。

#### 进程互斥的原则

为了实现对临界资源的互斥访问，同时保证系统性能，需要遵循以下原则：

- 空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区。
- 忙则等待：当已有进程进入临界区时，其他试图进入临界区的进程必须等待。
- 有限等待：对请求访问临界区的进程，要保证其在**有限的时间内进入**临界区。（保证不会饥饿）
- 让权等待：当进程不能进入临界区时，应当立即释放处理机，防止进程**忙等待**。

### 进程互斥的软件实现

#### 单标志法

1. 算法思想：进程访问完成临界区后，会把使用临界区的权限转交给另一个进程。即每个进程进入临界区的权限只能被另一个进程赋予。

2. 算法实现：

   <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301102315626.png" alt="image-20230110231532543" style="zoom:67%;" />

   - 问题：这种算法只允许进程按0-1-0-1这样轮流访问。如果当前是P0进程允许访问临界资源，但是P0进程没访问临界资源；那么虽然临界区空闲，但不让P1来访问。违背“空闲让进”原则。

#### 双标志法先检查

1. 算法思想：

   - 设置一个布尔数组，各个元素下标代表进程号，元素值代表进程想进入临界区的意愿。flag[0]=true代表进程0想进入临界区。

2. 算法实现：

   <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301112015710.png" alt="image-20230111201513581" style="zoom: 50%;" />

   - 检查另一个进程是否有进入意愿 - 表达意愿，上锁 - 使用临界资源 - 解锁
   - 问题：检查和表达意愿两步骤不是原子操作，如果中间发生了进程切换，会导致两个进程都把flag设为true了，都能访问临界资源。违反了“忙则等待”原则。

#### 双标志法后检查

1. 算法思想：
   - 先上锁，后检查。跟先检查法比，解决了违背忙则等待问题；但是还是老问题，如果不是上锁和检查不是原子操作，发生进程切换后会发生两个都是true但是两个进程都无法访问临界区的情况，违背了“空闲让进”和”有限等待“原则，各进程都容易导致饥饿。

#### Peterson算法

1. 算法思想：

   - 结合双标志法和单标志法。单标志法的turn变量表达谦让，用完之后将turn设为对方进程，对方可以进入；双标志法的数组表示进入意愿。

   <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202301112033429.png" alt="image-20230111203312327" style="zoom:50%;" />

   - while循环 ：flag[1] == true(即对方进程有意愿) && turn == 1（即自己最后谦让了使用权），就一直卡在循环里面检查，不进入临界区。
   - 实现了遵循空闲让进、忙则等待、有限等待三个原则；但是未满足“让权等待”原则；进不去临界资源的进程会一直在CPU上运行，不能直接让出CPU。 

### 进程互斥的硬件实现

#### 中断屏蔽

1. 利用开/关中断指令实现：
   - 关中断 - 临界区访问 - 开中断；关中断后，不允许当前进程被中断，也不会发生进程切换。直到当前进程访问完临界区，再执行开中断，其他进程才有可能上处理机并访问临界区。
2. 优点：简单高效；
3. 缺点：不适用于多处理机的情况；开关中断是特权指令，只适用于操作系统内核进程，不适用于用户进程。

#### TestAndSetLock指令

1. 算法思想：

   - 进入临界区前，先执行检测锁状态的算法，检测到锁是false的，就上锁并进入临界区。
   - lock共享变量是放在寄存器中的。

2. 算法实现：

   ```C
   //共享变量lock表示临界区资源是否被上锁。
   //true 表示已加锁；false表示未加锁。
   bool TestAndSet (bool *lock){
       bool old;
       old = *lock; //old用来存放锁原来的值
       *lock = true //不论锁的值是啥，都给他上锁
       return old; //返回lock原来的值
   }
   
   //使用TSL指令实现互斥的算法逻辑。
   while (TestAndSet (&lock)); //上锁 并检查
   //临界区代码段
   lock = false; //解锁
   //剩余区代码段
   ```

   - 如果lock本来就是true，执行TSL结果还是true，while就一直循环；如果lock是false，TSL就会加了锁，循环跳出，访问临界区结束再释放锁。

3. 优点：实现简单，适用于多处理机环境。

4. 缺点：使用while循环检测锁的算法，都存在着进程为了获取锁，一直卡在while循环在处理机上运行，不满足“让权等待”原则。

#### Swap指令

与TSL指令几乎一样。

## 信号量机制

### 背景

- 前面提到的进程互斥的解决算法中，四种软件实现方式和三种硬件实现方式；双标志检查法无法实现“检查”和“上锁”的一气呵成原子操作，从而导致进程可能同时访问临界资源。
- 所有的解决方案都无法实现“让权等待”。while循环使得等着抢占锁得我进程在处理机上运行。

- 1965年荷兰Dijkstra提出信号量机制，实现进程互斥和同步。

### 信号量介绍

- 信号量是一个变量【可以是整型、记录型】，可以用一个信号量来表示系统中某种资源的数量。比如系统中有一台打印机，可以设置一个初值为1的信号量。

- 用户进程可以使用系统提供的**一对原语**来对信号量进行操作，很方便的实现进程互斥和进程同步。

  > 原语是执行一气呵成、不可中断的特殊程序段。

  - 一对原语：wait(S)原语和signal(S)原语，函数名为wait和signal，括号里的信号量S是传入参数。
  - 一对原语也常称为P(S)、V(S)操作（来自荷兰语proberen和verhogen）。

### 信号量-整型

- 用一个整型变量表示信号量，表示系统中某种资源的数量。

  > 注意：与普通整型变量的区别，对信号量的操作只有三种：初始化、P操作、V操作。		

```C
int S = 1; //初始化信号量

void wait (int S){ //wait原语，相当于进入区，P操作
    while (S < = 0); //如果资源数量不够，就一直循环等待
    S = S - 1; //如果资源数量够，就占用一个资源
}

void signal (int S){ //signal原语，相当于退出区，V操作
    S = S + 1; //使用完资源后，在退出区释放资源。
}
```

- 优点：P、V都是原语，原子操作一气呵成，不会导致并发、异步导致的问题。
- 缺点：不满足**让权等待**原则，while循环一直卡着，还是会发生**忙等**。

### 信号量-记录型信号量

- 整形信号量缺陷是存在忙等现象，因此人们又提出了记录型信号量，用记录型数据结构表示的信号量。P操作是系统资源的申请，V操作是系统资源的释放。

  ```C
  //定义即记录型信号量
  typedef struct {
  	int value; //剩余资源数量
  	struct process *L; //等待队列
  } semaphore;
  
  //进程使用资源时，需要通过wait原语申请。wait原语也是自己写的
  void wait (semaphore S){
      S.vaule -= 1;
      if (S.value < 0){
          block (S.L); //剩余资源不够时，blobk原语会将进程从运行态改为阻塞态，并挂到信号量S的阻塞队列中。
      }
  }
  
  //进程使用完资源后，通过signal原语释放
  void signal (semaphore S){
      S.value += 1;
      if (S.value < = 0){  // 每个申请的进程都把信号量减1了，信号量值为负说明还有  进程在阻塞队列里面排队 
          wakeup(S.L); //那就唤醒一个进程
      }
  }
  ```


## 用信号量实现进程互斥、同步、前驱

### 进程互斥

1. 分析并发进程的关键活动，划定临界区（就是哪些代码是用于访问临界资源的）。（对临界资源打印机的访问就应放在临界区）

2. 设置互斥信号量mutex初值，代表临界资源的可用数量。（进入临界区的名额）。

3. 在进入区P，申请资源；在退出区V，释放资源。

   > - 对不同的临界资源，要设置不同的互斥信号量。
   > - P、V操作必须成对出现。

```C
//信号量定义
typedef struct {
	int value;
	struct process *L;
} semaphore;

//信号量机制实现互斥
semaphore mutex;
mutex.value = 1;

P1(){
    P(mutex); //加锁
    //临界区代码段
    V(mutex)；//解锁
}
```

### 进程同步

1. 让本来执行先后不可预知的并发进程，按要求的，有序推进执行。某个进程必须在另一个进程之后执行。解决并发进行的异步性。
2. 分析什么地方需要实现“同步关系”，即必须保证“一前一后”两个操作。
3. 设置同步信号量S=0；在前操作之后执行V；在后操作之前执行P（后运行的内容之前，上一把锁；等前序条件结束之后解锁）。

```C
//省略信号量定义
//信号量机制实现进程同步示例
semaphore S=0;

//假设代码4和5，必须在代码1和2之后进行。
P1(){
   代码1;
   代码2;
   V(S); //前置代码12执行完后，V操作解锁；信号量会+1，后面的P操作才能继续执行。
   代码3;
}

P2(){
    P(S); //后执行的代码前面加上锁，意味着前置代码12解锁之前，后置代码56不会执行。
    代码4;
    代码5;
}
```

- 如果P1先上处理机，那么12执行完之后解锁S++，P2后上处理机P可以执行下去；如果是P2先上处理机，由于S=0，P操作会直接把P2挂到阻塞队列中；等待P1的V执行完。

### 前驱关系

![image-20230318225836271](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202303182258483.png)

### 经典问题

#### 生产者消费者问题

- 问题描述

  - 系统中有一组生产者进程和一组消费者进程；生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区取出一个产品使用。

    （产品理解为某种数据，生产着消费者共享一个初值为空，大小为n的缓冲区，一个缓冲区的位置就叫一个空闲缓冲区）


  - 缓冲区有空位 - 生产者生产；缓冲区有数据 - 消费者消费

    > 这就意味着：缓冲区需要进程同步关系；缓冲区没满发生在先，生产者生产发生在后。
    >
    > 缓冲区没空 - V(full) - P(full) - 消费者消费 //P是在申请一个数据，信号量full应该是空闲缓冲区的数量


- 代码描述

  ```C
  semahphore mutex = 1; //互斥信号量，保证进程对缓冲区的互斥访问
  semahphore empty = n; //同步信号量，表示缓冲区里面空位的数量
  semahphore data = 0; //同步信号量，表示缓冲区内产品or数据的数量
  
  producer (){
      while (1){
          生产一个产品；
          P(empty);  //申请消耗一个空位，此时如果发现空位为0；则进程被挂起，无法往缓冲区内写数据。
          
          P(mutex)；//互斥信号量，保证缓冲区被互斥访问。
          向缓冲区内写数据；
          V(mutex);
              
          V(data); //释放一个数据资源以供消费者读取。
      }
  }
  
  consumer (){
      while(1){
          P(data); //申请消耗一个数据，如果此时缓冲区内没数据，消费者会被挂起
          
          P(mutex)；
          从缓冲区取出一个数据；
          V(mutex);
          
          V(empty); //释放一个缓冲区空位
          使用数据；
      }
  }
  ```

  - 实现互斥操作的信号量是成对出现，在同一进程中进行PV操作；同步信号量分别在两个进程中进行PV操作。
  - 注意：做V操作的进程，如果发现P操作的进程被挂起了，会唤醒该进程。
  - 注意：实现同步的P操作一定要在实现互斥的P操作之前，否则会出现死锁。（得先确定能去用，不会被挂起；再对资源加锁） 

#### 多生产者多消费者问题

#### 吸烟者问题

#### 读者写者问题

#### 哲学家问题

## 管程

- 为什么引入管程
  - 信号量机制，编程困难，容易出错。为了更方便的实现进程同步和互斥。
  - 1973年Pascal语言中引入

- 什么是管程
  - 用来实现进程同步，是一种特殊的软件模块。
    1. 对某种共享数据结构的说明
    2. 对该结构进行操作的一组函数
    3. 对共享数据设置初值的语句
    4. 管程有一个名字

- 基本特征
  - 在管程中定义共享数据（如产者消费者里面的缓冲区），共享数据是private的。
  - 在管程中定义一些函数，作为入口，用来访问共享数据。（比如生产者消费者里面的将产品放入缓冲区和将产品从缓冲区中取出的函数）
  - 入口可能有很多个，但是同时只允许一个入口开放，并且只能让一个进程或者线程进入。（这种互斥是由编译器实现的，程序员不必关心）
  - 可以在管程内设置一些条件变量和等待/唤醒操作，可以让进程或线程在条件变量上等待或被唤醒。

  > 程序员可以使用特殊的语法定义管程，比如 monitor ProducerConsumer ... end monitor;
  >
  > 之后其他程序员可以使用这个管程提供的入口来实现进程互斥同步 -> 即封装的思想

## 死锁

### 概念

- 死锁、饥饿、死循环的区别

  - 死锁：并发环境下，各个进程都在等待对方手里的资源，导致各个进程都被阻塞，都无法向前推进

  - 饥饿：某一个进程因为长期得不到想要的资源从而导致无法推进的现象。比如短作业优先算法中，长作业一直得不到处理机从而被阻塞。
  - 死循环：进程执行中，一直跳不出来某个循环；一般是bug或者故意设计的。

### 条件

以下条件缺一不可：

- 互斥条件

  必须是对互斥资源的争抢才会导致死锁。可以同时被访问的资源不会导致死锁。

- 不剥夺条件

  进程所获得的资源在未释放之前，不能被其他进程强行抢夺，只能由其主动释放。

- 请求和保持条件

​	每个进程都至少保持了一个资源，但是又提出了新的资源请求，而该资源又被其他资源占用；此时请求被阻塞，但是自己占用的资源保持释放。

- 循环等待条件

  存在资源的循环等待链，链中的每一个进程已获得的资源同时被下一个资源所请求。

  > 存在死锁一定存在循环等待；但是存在循环等待不一定存在死锁。
  >
  > 循环等待是必要不充分条件。
  
  如果同类资源大于1，即使有循环等待，也不一定发生死锁。进程可以获得新的资源来停止阻塞。

### 什么时候会发生死锁

- 对系统资源的竞争

  各进程对不可剥夺资源（如打印机）的竞争可能会引起死锁。对可剥夺的资源（如CPU）的竞争不会引起死锁。

- 进程推进顺序非法

- 信号量使用不当

  比如实现互斥的P操作，发生在实现同步的P操作之前，就会发生死锁。

> 总之，对不可剥夺资源的不合理分配，会导致死锁。

### 死锁的处理策略

**不允许死锁发生**

- 静态策略：预防死锁

  - 破坏互斥条件

    互斥条件：必须是对互斥使用的资源的争抢才会导致死锁。

    操作系统可以采用SPOOLing技术，把独占设备改造成共享设备。（有些时候设备的互斥性是必须的，这种方法会有局限性）

  - 破坏不剥夺条件

    方案一：当某个进程申请的新资源得不到满足时，就会被要求立即释放占有的所有资源，待以后需要时再重新申请。

    （容易导致该进程饥饿）

    方案二：某个进程需要的资源被占有时，可以由操作系统协助，将想要的资源强行剥夺。这种方式要考虑各个进程的优先级。

    （比如剥夺调度方式，将处理机强行剥夺给更高优先级的进程使用。比较复杂，适用于容易恢复现场的资源，如CPU）

  - 破坏请求和保持条件

    可以采用静态分配方法：进程运行前需要一次性申请完所有需要的资源；一旦投入运行，占有的资源就一直归他所有，不会申请新的资源。

    （容易造成资源浪费）

  - 破坏循环等待条件

    采用顺序资源分配法：给资源编号，规定每个进程必须按编号顺序递增的方式请求资源。同类资源一次申请完。

    一个进程只有占有小编号资源时，才能申请大编号资源 ，不能反过来申请。

    （不方便增加新的设备，因为要重新给所有资源编号；编号顺序和进程使用资源的顺利不一定一致，可能造成资源浪费。）

- 动态策略：避免死锁 - 银行家算法

  > 银行家算法背景：假如你是一个银行家，手里有100亿资金；3个企业向你借钱，每个企业最多借走n1-n3亿元。但是有规定：如果借给某个企业的钱低于这个企业最多需要的钱，这些钱是回不来的（换言之只有满足了最多要借的资金需求，才会还钱）。所以存在一个安全序列，按某个顺序借钱出去，能满足收回资金，不会无钱可借出。

  - 按照某个顺序分配资源，每个进程都能完成而不死锁。如果系统中可以找到安全序列，那肯定不会发生死锁；如果系统进入不安全状态，那可能会发生死锁。

  - 在分配资源之前，提前判断这次分配会不会让系统进入不安全状态，以此判断是否允许这次分配请求。

  - 实现方法：

    ![image-20230405171913958](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304051719159.png)

  

**允许死锁发生**

死锁的检测与解除

- 死锁的检测

  用一种数据结构：资源分配图，来检测死锁。R表示资源，P表示进程，蓝色的边，表示进程正在申请资源；绿色的边表示资源已经被分配出去了。

  ![image-20230405173755856](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304051737016.png)

​	如果某个时刻，是不能完全简化的，那就说明发生了死锁。

- 死锁的消除

  - 资源剥夺法：暂时挂起某些死锁进程，抢占他们的资源。但是应防止被剥夺的资源长期处于饥饿状态。

  - 撤销进程法：直接强行撤销一些进程。但是这样做代价较大。

  - 进程回退法：让某些进程回退到足以避免死锁的程度。这需要系统记录历史状态，设置还原点。

    

# 第三章 内存管理

## 内存基础

### 内存的编址

按字节编址/按字长编址

### 指令的工作原理

- 代码要翻译成CPU能够识别的指令，会告诉CPU去哪个内存地址读写数据，数据作什么样的处理。
- 程序经过编译链接，生成的机器指令，指明的是逻辑地址（相对地址），即相对于进程的起始地址而言的地址；而不是实际的物理地址。

### 逻辑地址转换物理地址

1. 绝对装入
   - 如果知道程序将放到内存中的哪个位置，编译时，直接产生绝对地址的目标代码。
   - 装入模块（可执行文件）中已经写死了绝对地址，那么意味着这个程序换一个环境就不能保证正确运行。
2. 可重定位装入（静态重定位）
   - 装入模块中还是写入的逻辑地址，等到装入模块进入内存时，对地址进行转换，变为物理地址。（地址变换是在装入时一次完成的）
   - 特点是要求一个作业装入内存时，必须分配其要求的全部内存空间。并且在运行期间就不能移动。
3. 动态运行时装入（动态重定位）
   - 装入模块、以及装入模块进入内存时都是使用的逻辑地址；等到程序真正执行时，才会执行逻辑地址 - 物理地址的转换。
   - 这种方式需要重定位寄存器的支持；重定位寄存器放着程序的起始位置，某条指令运行时，用逻辑地址加上起始位置，得到物理地址。
   - 这种方式：允许程序分配到不连续的内存空间，程序运行前只需部分代码即可，可根据需要动态申请内存。

### 程序是怎么跑起来的

#### 步骤

- 源代码文件 - 编译 - 目标模块文件（即机器语言，使用逻辑地址）- 链接 - 装入模块（可执行文件）- 装入内存中

  - 编译：由编译程序将源代码编译成若干个目标模块
  - 链接：由链接程序将编译后的一组目标模块，和需要的库函数链接在一起，形成完整的装入模块。

  ![image-20230405230244935](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304052302927.png)

#### 链接的三种方式

1. 静态链接

   程序运行之前，现将各个目标模块和所需的库函数连接成一个完整的可执行文件，之后不再拆开。

2. 装入时动态链接

   将各个目标模块装入内存时，一边装入一边链接

   <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304052305281.png" alt="image-20230405230517146" style="zoom:50%;" />

3. 运行时动态链接

   在程序执行中需要该目标模块时，才对其进行链接；用不到的模块不链接。灵活性较高，便于修改更新。

## 内存管理

操作系统要负责系统内存的管理，其中包括：

1. 内存空间的分配与回收
2. 内存空间逻辑扩充
3. 逻辑地址和物理地址的转换（地址重定位）
4. 内存保护，即进程之间分配的内存空间不能互相访问。
   - 采用重定位寄存器（基址寄存器）和界地址寄存器（限长寄存器）进行越界检查。
     - 重定位寄存器存放起始物理地址，界地址寄存器存放最大逻辑地址。
     - 进程访问某个地址时，会首先通过界地址寄存器检查是否越界；不越界的话，再与基址寄存器的起始物理地址相加，得到物理地址。

### 覆盖与交换

- 覆盖技术

  ![image-20230406224858801](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304062248036.png)

> 需要由程序员声明覆盖条件，增加难度；目前不再使用

- 交换技术

  - 思想：当内存空间紧张时，系统将内存中某些进程暂时换出到外存，把外存中某些已具备运行条件的进程换入内存。（中级调度）
  - 中级调度中PCB还是会被留在内存中，被放到挂起队列，用来记录金程被放到了外存中的什么位置。
  
  > 1. 交换到外存的什么位置？
  > 2. 什么时候应该交换？
  > 3. 应该交换哪些进程？
  
  1. 具有交换功能的操作系统中，磁盘空间会被分为：文件区和交换区
  
     文件区存放文件，追求空间利用率，因此采用离散分配方式。交换区空间较小，被换出的进程数据就存放在交换区，由于交换区的速度直接影响了系统速度，所以交换区追求；换入换出速度，故而采用连续分配方式，IO速度比文件区更快。
  
  2. 交换通常发生在内存吃紧时，例如：发现许多进程运行时经常发生缺页，此时说明内存紧张，需要换出一些进程。
  
  3. 可优先换出阻塞进程；或者优先级低的进程。为防止进程饥饿，也会考虑进程在内存中的驻留时间。（PCB会常驻内存，不被换出）

### 内存空间的分配与回收

#### 连续分配管理方式

为用户进程分配的是一个连续的内存空间。

- 单一连续分配

  - 内存分为系统区和用户区，用户区只能有一道用户程序，用户程序独占整个用户区空间。不支持多道程序并发。

  - 缺点：会产生内部碎片。

    > 内部碎片：分配给进程的内存区域中，如果有部分没有用上，处于空闲状态，这部分区域就是“内部碎片”

- 固定分区分配

  - 为多道程序设计，将用户空间划分为若干个固定大小的分区，每个分区中装入一道作业，形成了最早的多道程序内存管理方式。

  - 特别适合用一台计算机控制多个相同对象的场合（钢铁厂有n个炉子，可以把内存分为n个大小相等的区域存放n个炉子控制进程）

    > 操作系统如何实现分区的分配和回收？
    >
    > 操作系统需要建立一个数据结构 - 分区表，来实现，其中每个表项对应一个分区，记录分区的大小、起始地址、状态。

  - 优点：无外部碎片；

  - 缺点：

    - 如果用户程序太大，所有分区都不能满足要求，要采用覆盖技术，但这会降低性能；
    - 分区是预先设定好的大小，会产生内部碎片，内存利用率低。

- 动态分区分配

  - 不会预先设定分区大小，而是在进程装入内存时，根据进程的大小，动态建立分区，使其适合进程大小。

    1. 系统是用什么数据结构记录内存使用情况？

       - 使用空闲分区表或者空闲分区链

         <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304081013458.png" alt="image-20230408101333223" style="zoom:50%;" />

    2. 当很多个空闲分区满足需求是，应该选择哪个进行分配？

       - 新作业装入内存时，必须按照一定的动态分区分配配算法，从空闲分区中选出一个来分配。

    3. 如何进行分区的分配和回收？

       - 分配：表项或者链表节点的增删。
       - 回收：回收区与空闲分区相邻时，合并空闲分区，更新起始地址。

> - **内部碎片：分配给进程的内存区域中，某些部分没有用上。**
>
> - **外部碎片：内存中的某些空闲分区因为太小而难以利用。**
>   - 内存中总共的空闲区域本来可以满足某些进程的要求，但是由于进程需要一整块的连续区域，因此这些碎片不能满足要求。
>   - 可以通过Compaction技术来拼凑外部碎片。 

##### 动态分区分配算法

- 首次适应算法：每次从低地址开始查找，找到第一个能满足大小的空闲分区。
- 临近适应算法：每次从低地址开始查找，空闲分区表形成一个循环链表，每次查找都从上一次结束的位置开始找，找到大小满足的第一个空闲分区。（算法开销小，大师会师大地址的大分区也被用完）
- 最佳适应算法：优先使用更小的空闲分区，避免浪费。空闲分区会按容量次序递增来链接，每次分配内存时顺序找到第一个能满足的空闲分区。（会产生很多外部碎片）
- 最坏适应算法：优先使用更大的空闲分区。这样分配后，剩余的空闲分区就不会太小，更方便使用。（大分区被消耗，大进程容易没有分区可用）

### 分页的概念

- 什么是分页管理

  - 将内存空间分为一个一个的大小相等的分区（比如每个分区4KB），每个分区是一个*页框/页帧/内存块/物理块/物理页面/Page Frame*，页框号从0开始。

  - 将进程的逻辑地址空间也分为与页框大小相等的一个个部分，每一个部分称为*页*或*页面*，每一个页也有编号，即页号，从0开始。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304081514368.png" alt="image-20230408151416178" style="zoom:50%;" />

  - 操作系统以页框为单位，为各个进程分配内存空间。进程的每个页面分别放入一个页框中。进程的页和内存的页框有一一对应的关系。

    （各个页面无需连续存放，可以放到不相邻的各个页框之中）

  - 操作系统为识别进程的每个页面在内存中的存放位置，需要建立一个**页表**，页表往往放在PCB中。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304081525878.png" alt="image-20230408152506753" style="zoom:50%;" />

  - 页表项，逻辑上包含了页号和块号的信息；物理上只存储块号就行了。页号标识进程的页，相当于数组下标。无需额外存储。
  - 地址转换：如果已知进程内的某个逻辑地址，需要计算物理地址
    - 获取该逻辑地址在进程内的页号
    - 通过页号，查页表，获得内存里面的页框号（起始地址）
    - 通过该逻辑地址的页内偏移量，来计算出该逻辑地址对应的物理地址

### 非连续分配管理方式

#### 基本地址变换机构

> 用于实现逻辑地址到物理地址转换的一组硬件结构

- 页表寄存器
  - 存放页表在内存中的起始地址、页表长度。
  - 进程未执行时，页表起始地址和长度放在进程控制块PCB中；当进程被调度时，操作系统会把他们放到页表寄存器中。                                                    

- 逻辑地址与物理地址的转换

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304091448689.png" alt="image-20230409144830425" style="zoom:50%;" />

> 分页式存储管理中，只要确定了每个页面的大小，逻辑地址结构就确定了。只要给出一个逻辑地址，系统就会自动算出页号、页内偏移量。
>
> 因为只需要告诉系统逻辑地址即可，分页式存储管理是一维的。

#### 快表地址变换

- 快表，又称为联想寄存器（TLB），是一种比内存快很多的**高速缓存**。用来存放最近访问的页表项副本，加速地址变换的速度。与此对应，内存中的页表称为慢表。（TLB只存放页表的副本，与其他种类的cache不同）

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304091618871.png" alt="image-20230409161823756" style="zoom:50%;" />

- 如果命中快表缓存，那就不需要访问慢表；加速系统速度。 基于局部性原理，快表的命中率一般可打90%以上。 

  > 时间局部性：如果执行了程序中的某条指令，不久后这条指令很有可能再次被执行。（因为程序中存在大量的循环）
  >
  > 空间局部性：一旦程序访问了某个存储单元，其附近的存储单元也很有可能被访问。（因为很多数据在内存中都是连续存放的）	

#### 两级页表

- 单级页表存在什么问题？
  - 需要大量连续页框存放进程的页表项，违背离散型存储原则；
  - 根据局部性原则，页表项不需要一次性全部读入内存。
  
- 两级页表的设计

  - 将长长的单级页表，拆分成若干个分组，使得每个内存块刚好放入一个分组，离散的放在内存中。

  - 再为离散分配的页表，再建立一张页表，称为页目录表，或者顶层页表。

  - 采用两级页表后，逻辑地址的结构也发生了变化：

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304102245173.png" alt="image-20230410224548893" style="zoom:50%;" />

- 如何实现在需要访问页面的时候才把页面调入内存？

  - 顶层页表中添加一项标志位，标志该页面是否已经调入内存。如果不在，会产生缺页中断，将页面从外存调入内存。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304102250428.png" alt="image-20230410225027184" style="zoom:50%;" />

- 两级页表的对内存的访存次数会增加。n级页表，需要访存n+1次。

### 基本分段存储管理

#### 分段

- 与分页最大的区别是离散分配时所分配的存储空间基本单位不同。

- 进程按照自身逻辑，划分成若干段，每段由一个段名，每段从0开始编址。

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304160911802.png" alt="image-20230416091146683" style="zoom:50%;" />

- 段名 - 段号：段名可以编程时用，操作系统将段名转换为段号

#### 逻辑地址

- 分段系统的逻辑地址由：段号+段内偏移量组成
  - 段号决定了每个进程可以有多少个段；段内偏移量决定了每个段的大小

#### 段表

- 为每个进程建立段映射表

  - 便于从物理内存中找到每个逻辑段的存储位置。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304160923431.png" alt="image-20230416092303312" style="zoom:50%;" />

  - 基址表示段在物理内存中的起始位置

  - 每个段表项的大小是相同的，所以段号可以是隐藏的，不占用存储空间。

- 内存中的系统区中存放着许多用于管理系统软硬件资源的数据结构，包括进程PCB

  - 当一个进程要上处理机运行之前，负责进程切换的内核程序负责恢复进程运行环境。
    - 就包括，在段表寄存器中恢复：该进程的段表在内存中的存放位置

- 段表同样可以放入快表机构中，减少访问内存次数。

#### 分段与分页

- 页是信息的物理单位，主要为了实现离散分配，提高内存利用率。仅仅是物理上的需要，完全是系统行为，对用户不可见。
- 段是信息的逻辑单位，是按逻辑模块来划分的，分段是为了满足用户编程需求，分段对用户是可见的。

### 段页式管理方式

- 分段、分页式的优缺点

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304161125213.png" alt="image-20230416112516102" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304161126142.png" alt="image-20230416112619072" style="zoom:50%;" />

#### 段页式管理

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304161434980.png" alt="image-20230416143446827" style="zoom:50%;" />

- 先分段，段内再分页；可以理解为：每个段，对应一个页表

  - 逻辑地址的组成：**段号 - 页号 - 页内偏移量**
    - 用户只需要给出某个逻辑地址的段号和段内地址，系统会自动将段内地址转换为页号+页内偏移量。

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304161617610.png" alt="image-20230416161711432" style="zoom:50%;" />

  - 地址转换需要3次访存：访问段表 - 访问页表 - 访问实际物理地址（内存块号+页内偏移量）

- 也可以引入快表机制，用段号和页号作为查询快表的关键字，减少访存次数。

- 进程访问非法地址，会产生Segmentation Fault，系统将进程杀掉，产生core dump。

## 虚拟内存

- 传统存储管理方式的特征
  - 一次性：作业必须一次性装入内存。
  - 驻留性：一旦作业被装入内存，就会一直驻留，直到作业运行结束。

### 局部性原理

- 时间局部性
- 空间局部性

### 虚拟内存的定义与特征

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304161942575.png" alt="image-20230416194204392" style="zoom:50%;" />

### 虚拟内存的实现

- 首先要基于离散型内存管理方式，针对不同的离散存储方式，有不同的虚拟内存实现方法。

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304161943069.png" alt="image-20230416194353925" style="zoom:50%;" />

### 请求分页存储

- 主要功能
  - 当程序执行时，所访问信息不在内存中时，由操作系统负责将所需信息从外存调入内存，继续执行。【换入】要操作系统提供请求调页功能，将内存缺页调入。
  - 若内存空间不够，操作系统负责将内存中用不到的信息换出到外存。【换出】操作系统要提供页面置换功能。

#### 页表机制

- 与基本页表相比，请求分页管理中，为实现请求调页，操作系统需要知道：每个页面是否已经调入内存；如果还没调入，也需要知道该页面在外存中存放的位置。

- 当内存空间不够时，实现页面置换，操作系统需要决定换出哪些页面；并且需要记录页面是否被修改过，如果没有被修改过，就不需要浪费时间将页面写回外存。

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304162023479.png" alt="image-20230416202310339" style="zoom:50%;" />

- 请求分页系统中，当某个页面不存在内存时，产生一个缺页中断，由操作系统的缺页中断程序来处理中断。此时该进程阻塞，进入到阻塞队列，完成调页后将其唤醒，放回就绪队列。
  - 如果内存中有空闲块，分配一个给进程，将缺页装进去，修改一下页表项
  - 如果进程中没有空闲块，由页面置换算法选择一个页面淘汰；如果被淘汰页面在内存期间被修改过，就写回外存，否则就不用写回。

#### 缺页中断

进程请求访问了还没调入内存的页，属于是内中断

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304162108272.png" alt="image-20230416210833111" style="zoom:50%;" />

#### 快表

- 快表中的页表项一定是在内存中存在的，如果某个页表项被移出内存，快表中相应的表项也要被删除，防止访问错误页面。
- 如果某个页面被修改过（即执行了写指令），那么只会更新快表中的修改位，直到该页面被调出内存时，快表中的表项删除前会写入到慢表中，减少访存次数。
- 页面被调入内存时，需要修改慢表，同时将表项复制到快表
  - 发生缺页时，地址变换步骤是：查快表（未命中）- 查慢表（发现未调入内存）- 调页（慢表表项会复制到快表）- 直接查快表（命中，获得物理地址）- 访问目标单元

### 页面置换算法

页面的换入换出，需要磁盘IO，会有较大的开销，因此更好地页面置换算法应该追求更少的缺页率。

#### 最佳置换算法

- **提前知道了进程访问页面号的顺序**，当发生缺页时，优先换走后面最长时间内不会被使用的页面。来保证最高的缺页率。
- 实际上，无法预知进程访问哪些页面，所以这个算法无法实现。

#### 先进先出算法

- 每次淘汰的页面是最早进入内存的页面。

- 把调入内存中的页面按照先后顺序排成一个队列，需要换出时，选择队头页面换出。队列的长度取决于操作系统为进程分配了多少内存块。

  > 会出现Belady异常：当为进程分配的内存块数增大时，反而会增加缺页次数的异常现象。
  >
  > 只有FIFO算法会出现Belady异常，算法性能很差。

#### 最近最久未使用置换算法（LRU，last recently used）

- 每次淘汰的页面是最近最久未使用的页面。
- 使用方法：页表项中，用访问字段记录该页面自上次访问以来所经历的时间t，调出页面时，选择t值即可。
- 该方法性能最好，最接近最佳置换算法，但是实现困难，需要专门的硬件支持。

#### 时钟置换算法（CLOCK）

也叫**最近未用算法（NRU，Not Recently Used）**，性能和开销比较均衡。

- 简单CLOCK算法

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304162205486.png" alt="image-20230416220536323" style="zoom:50%;" />

- 改进型clock算法

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304162225394.png" alt="image-20230416222501115" style="zoom:50%;" />

### 页面分配策略

#### 驻留集

- 采用了虚拟存储的系统中，驻留集的大小一般小于进程的总大小。

- 若驻留集太小，会导致缺页频繁，系统花费大量时间处理缺页，实际用于进程的时间很少；驻留集太大，导致多道并发度下降，利用率降低。所以要有一个合适的驻留集大小。

#### 分配大小和置换策略

**分配大小**

- 固定分配：驻留集在进程运行期间大小不变
- 可变分配：动态调整驻留集

**置换策略**

- 局部置换：发生缺页时，只能将自己的物理块进行置换。

- 全局置换：将内存空闲的物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，分配给缺页进程。

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304172054612.png" alt="image-20230417205448466" style="zoom:50%;" />

**固定分配-局部置换**

系统为每个进程分配一定数量的物理块，如果发生缺页，只能从该进程页面中选出一页换出。缺点是一开始难以确定每个进程初始分配多少。

**可变分配-局部置换**

系统为每个进程分配一定数量的物理块，如果发生缺页，只能从该进程页面中选出一页换出；如果频繁缺页，系统会为该进程多分配几个物理块；反之亦然。

**可变分配-全局置换**

系统为每个进程分配一定数量的物理块，系统会保持一个空闲物理块队列，某进程发生缺页时，从空闲物理块中选一个分配。若没有空闲物理块，则选择一个未锁定的页面换出外存，分配给缺页者。因此只要进程发生缺页，都会获得新的物理块。

#### 何时调入页面

- 预调页策略

  根据空间局部性原理，一次调入若干个相邻页面比只调入一个页面更高效。可以预测不久后可能访问到的页面，预先调入内存，但目前预测成功率只有50%左右。所以这种策略只要用于进程的首次调入。

- 请求调入策略

  运行期间发生缺页时才将所缺页面调入内存，这种策略调入页面一定会被访问到。但由于每次只能调入一页，每次调页都用到磁盘IO操作，因此IO开销较大。

#### 何处调入页面

![image-20230417211515687](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304172115867.png)

#### 抖动现象

- 刚刚换入的页面又要换出，刚刚换出的页面又要换入。这种频繁页面调度称为抖动/颠簸。
- 产生抖动的原因是进程频繁访问的页面数目高于可用的物理块数。（分配给进程的物理块不够）
- 为进程分配太多或太少都不合适，为研究应该为每个进程分配多少物理块，提出了工作集的概念。

#### 工作集

- 驻留集：请求分页管理方式中，给进程分配的内存块的集合。

- 工作集：在某个时间间隔内，进程实际访问的页面的集合

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304172144618.png" alt="image-20230417214429452" style="zoom:50%;" />

## 文件管理

### 概述

> 1. 一个文件有哪些属性？
> 2. 文件内部的数据应该怎样组织起来？
> 3. 文件之间应该怎样组织？
> 4. 操作系统为上层应用提供哪些易用的接口？
> 5. 文件应该怎样存放在外存上？

#### 文件的属性

- 文件名
- 标识符（系统使用）
- 类型、大小、创建时间、上次修改时间
- 位置（文件存放路径：用户使用；文件在外存中的位置：系统使用）
- 保护信息

#### 文件内部数据的组织

- 无结构文件/流式文件 （如文本文件）：有一系列二进制字符流组成。
- 有结构文件/记录式文件（如数据库表）

#### 文件之间的组织

- 目录：也是一种有结构文件

#### 操作系统向上提供哪些功能？

- 创建、读、写等，应用程序调用了操作系统提供的：create、read、write等系统调用

#### 文件应该如何放到外存？

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304202213207.png" alt="image-20230420221324905" style="zoom:50%;" />

### 文件的逻辑结构

> 逻辑结构：用户看来，文件内的数据是怎样组织的；物理结构：操作系统看来，文件的数据是怎样放在外存中的。

- 无结构文件：流式文件，由一连串的二进制或字符流组成。
- 有结构文件：记录式文件，由一组记录组成，每个记录有个主键。

#### 有结构文件的逻辑结构

- 顺序文件

  - 顺序存储：逻辑上相邻的，物理上也相邻
  - 链式存储：类似于链表，逻辑上相邻的物理上不一定相邻
  - 串结构：记录之间顺序与关键字无关
  - 顺序结构：记录的顺序按关键字顺序排列

- 索引文件

  - 由于可变长记录的文件，不支持随机检索，只能从头找；为了使可变长记录的文件易于查找，可建立索引。

  - 维护一个索引表，加快文件检索速度

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304221633541.png" alt="image-20230422163309411" style="zoom:50%;" />

  - 可以针对不同的关键字建立索引；可以根据关键字快速检索文件。

  - 索引表记录文件中的各个记录的逻辑地址，查询索引表之前，会先将索引表调入内存中的：文件信息缓冲区。

- 索引顺序文件

  - 为了解决索引文件占空太大的问题。

  - 对文件中的记录进行分组，每个组对应一个索引表项

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304221640685.png" alt="image-20230422164017514" style="zoom: 50%;" />

  - 若想查找某个顺序文件中的某条记录：先二分查找索引顺序文件中的分组，找到分组后再在分组里面顺序查找 

- 多级索引顺序文件
  - 给低级索引顺序表再建立一个高级索引顺序表

### 文件目录

>  操作系统是如何实现文件目录的？

#### 文件控制块

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304221658587.png" alt="image-20230422165813370" style="zoom:50%;" />

- 每个目录，都是一个目录文件，里面包含着子目录、文件的各项信息。
- 一个文件控制块（FCB）就是目录文件中的一条记录。FCB主要是实现文件名 - 文件外存地址的映射，使得用户可以按文件名存取。
- 对文件的增删改查，也要对FCB做改动。

#### 目录结构类型

- 单级目录结构
- 两级目录

- 树形目录结构

- 无环图目录结构

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304221716098.png" alt="image-20230422171559970" style="zoom: 50%;" />

​	不同用户可以创建link，访问到同一文件，方便了文件共享。

#### 索引节点改进

- 实际检索目录的时候，只需要用到文件名，只有文件名匹配的时候，才需要读出其他信息；可以基于此给目录表瘦身

  - 可以把除文件名之外的其他信息放到“索引节点”中，目录表中只留下文件名和索引节点指针。

  - 每个文件都对应一个索引节点（inode）

  - 当文件名被找到后，才需要将索引结点调入内存；调入前叫“磁盘索引结点”，调入后叫“内存索引结点”。（内存索引结点中会增加：是否被修改、进程访问情况等信息）

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304221731051.png" alt="image-20230422173101870" style="zoom:50%;" />

- 每次IO操作只能读取一个磁盘块，所以如果目录表很大的话，读一个文件造成的IO会很高；给目录表瘦身之后，占用的磁盘块小了，IO就低了，读的就快一些了。

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304222210675.png" alt="image-20230422221055595" style="zoom:50%;" />

> 从pwd（当前路径）出发检索文件会减少磁盘IO次数。因为每查询下一级目录的时候都需要启动磁盘IO，把下一级的目录文件从外存调入内存。

### 文件保护

- 口令保护
- 加密保护

- 访问控制

  - 访问控制表：在每个文件的FCB中增加一个访问控制表（ACL），该表中记录了各个用户可以对文件执行哪些操作。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304222134961.png" alt="image-20230422213412833" style="zoom:50%;" />

  - 精简的访问控制表：

    以组为单位，标记各个组内的用户可以对文件执行哪些操作。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304222136253.png" alt="image-20230422213640163" style="zoom:50%;" />

###  文件共享

- 基于索引结点的方式（硬链接）

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304222212097.png" alt="image-20230422221229008" style="zoom:50%;" />

  - 索引结点维护一个共享数量count，表示该文件有多少个硬链接的共享。
  - 某个user删除文件后，只是删除了目录表项和与索引结点的链接；只有当count降为0时，才会真正删除文件的物理数据。

- 基于符号链的方式（软链接）

  <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304222216881.png" alt="image-20230422221626748" style="zoom:50%;" />

  - 软链接到该文件，相当于建立了一个新的文件，只不过这个文件是link类型，会记录链接文件的路径。访问软链接文件时，系统根据路径找到源文件的索引结点。
  - 因为软链接访问文件要访问多级目录，因此会比硬链接的磁盘IO更高。


### 文件的物理结构

> 对空闲/非空闲磁盘块的管理

- 磁盘中的存储单元也被分为磁盘块/物理块；很多操作系统中，内存的页面大小与磁盘的块大小相同。数据交换比较方便。
- 内存与磁盘的IO操作是以块为单位，每次读出或写入一个块。
- 同时，文件自身也被分成了块。假设分的块是1kb，文件大小是1mb，那么文件就被分成1024个块，块号为0~1023。每一个逻辑地址都由块号+块内地址组成。
- 那么，文件存到外存时，文件的逻辑地址要被映射为外存的物理地址，操作系统负责实现二者的映射。

#### 文件数据怎样存放在外存中

- 连续分配

  - 要求每个文件在磁盘上占有连续的块 
  - 用户给出逻辑块号，操作系统找到FCB（记录了这个文件的起始块号和长度），物理块号=起始块号+逻辑块号。
  - 优点：支持顺序访问和随机访问。缺点：不方便扩展文件大小；空闲块难以利用。产生磁盘碎片    

- 链接分配

  - 隐式链接

    - 文件的FCB记录了文件的起始块号和结束块号；文件的每个磁盘块都记录了指向下一个块的指针
    - 用户给出逻辑块号，操作系统找到FCB（记录了这个文件的起始块号），读入起始块，像链表一样读到第i号（产生i+1次IO）。
    - 优点：方便扩展文件，不产生碎片。缺点：只支持顺序访问，而且占用一定空闲存储指针。

  - 显示链接

    - 用于链接文件各个物理块的指针，显式的统一放到一张表中（文件分配表，FAT）

      <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304242222922.png" alt="image-20230424222213880" style="zoom:50%;" />

      - FAT开机读入内存并常驻内存。
      - 地址转变：用户给出逻辑块号，操作系统找到FCB（记录了这个文件的起始块号），直接读FAT，找到第i块。不需要磁盘IO。
      - 优点：支持顺序和随机访问，不需要磁盘IO；不会产生外部碎片。

- 索引分配

  - 允许文件离散分配，系统为每个文件建立索引表，记录文件逻辑块对应的物理块。
  - 索引表也放在磁盘上，放索引表的磁盘块叫索引块，放文件数据的磁盘块叫数据块。
  - 文件的FCB中需要记录该文件的索引块，访问文件时先访问文件的索引表，根据逻辑块号找到物理块号，再访问物理块。

  （FAT是一个磁盘存一个；索引表是一个文件存一个。）

  - 优点：支持顺序和随机访问，方便扩展文件

  - 可以采用多级索引表：来解决一个文件的索引表太大，占用多个磁盘块，导致磁盘IO过高的问题。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304242251677.png" alt="image-20230424225112557" style="zoom:50%;" />

    - 多级索引表的地址转换：
      1. 已有条件:要访问的逻辑地址、FCB，采用两级索引。
      2. 首先根据逻辑地址除以索引表占用块的大小，得到这个逻辑地址在哪个二级索引表里面。
      3. 再根据逻辑地址对索引表占用块的大小取余，得到表内偏移量。
      4. 这时候根据FCB记录的顶级索引表的物理块号，读入顶级索引表，读出相应的二级索引表的物理地址，再读入二级索引表，查表内偏移量，找到逻辑地址对应的物理地址。
  
  - 可以采用混合索引，顶层索引表中既有直接地址索引（指向数据块），又有间接索引（指向下一级索引表）。这样解决了多层索引里面读取小文件也需要多次磁盘IO的问题。

### 逻辑结构vs物理结构

- 用户视角看到的文件：占用一片连续的逻辑地址空间。
- 操作系统视角看到的文件：先给文件分块，给每个块编上块号，逻辑块号相邻，然后分配到外存中。
- 作为文件的使用者，用户指出想访问的逻辑地址，操作系统会将逻辑地址转变为逻辑块号和块内偏移量，再转变为物理地址，进行实际访问。

- 链式存储vs链接分配
  - 顺序文件的链式存储：是指文件的内部，各个块之间的逻辑顺序是按链表方式存储的，这是由用户决定的
  - 文件在外存的链接分配：由操作系统决定。

- 索引文件vs索引分配

  - 索引文件：文件创建者自己创建索引表，索引表的映射是：关键字 - 记录存放位置的逻辑地址

    - 如下实例是用索引表，通过学号定位到该学生的姓名等信息。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304252256798.png" alt="image-20230425225610556" style="zoom:50%;" />

  - 索引分配的索引表：由操作系统建立，映射是：逻辑块号 - 物理块号。

### 文件存储空间管理

#### 存储空间的划分与初始化

- 磁盘分区

  - 分为CDE盘就是将物理磁盘分为若干个文件卷（逻辑卷），每个文件卷又分为目录区和文件区。

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304262140126.png" alt="image-20230426214046909" style="zoom:50%;" />

    

  - 初始化就是将文件卷划分目录区和文件区

#### 存储空间管理

- 空闲表法

  - 维护一个空闲表，记录第一个空闲盘块号和他后面连续空闲的块数。
  - 适用于连续分配方式，可用类似于内存动态分区分配算法的分配方式。

  - 空间回收时，合并空闲表的项

- 空闲链表法

  - 空闲盘块链：

    - 每一个空闲盘块指向下一个空闲盘块
    - 操作系统维护链头和链尾指针，分配空闲块时，从链头开始分配出去，修改一下链头指针；回收空间时，新空间挂到盘尾，修改链尾指针。

    - 适用于离散分配

  - 空闲盘区链：

    - 盘区是指连续的盘块；每个空闲盘区指向下一个区

    - 分配空闲块：从链头检索合适的空闲盘区，没有合适的话也可以分配到不同的盘区；回收：合并到空闲盘区或单独挂到链尾。
    - 相比空闲盘块，效率更高。

  > 空闲表法和空闲链表法不适用于大型文件系统，因为空闲表或空闲块过大

- 位示图法

  ![image-20230426224747791](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304262247950.png)

  - 这里位号是16个，就表明前16个块字号是1；17个块往后字号就是2
  - 分配空闲块：根据位示图找到相邻或不相邻的块来分配，相应位置置为1；回收时根据盘块号计算出字号和位号，置为0。

- 成组链接法

  - UNIX采用成组链接法对空闲块进行管理

  - 工作原理：

    ![image-20230427214637920](https://raw.githubusercontent.com/hangx969/upload-images-md/main/202304272146028.png)

    - 把空闲盘块分了组，每个组包含的空闲盘块数量一定。
    - 每个分组的第一个盘块，负责记录后一个分组的信息（下一个分组的头结点的位置，下一个分组的大小），就这样串起来。
    - 逻辑卷的目录区维护一个超级块，系统启动时将超级快读入内存，保持内存与外存中的超级块保持一致。超级块会保存第一个分组的信息。分组进行新建或分配时，需要修改超级块的信息，使其一直指向第一个分组。
    - 分组内部相当于一个栈的结构，栈顶先被分配，分配到栈底，就读出下一个分组的信息，继续分配。
    - 当栈底记录了下一个分组信息的磁盘块被分配之前，会把该信息复制到超级块，避免与后面的链接丢失。

### 文件的基本操作

操作系统向上提供的功能：

- 创建文件：create系统调用

  - 需要提供的参数：所需外存大小、文件存放位置、文件名
  - OS做的事情：
    - 在外存中找到文件所需的空闲空间
    - 根据文件路径找到目录文件，在目录中创建该文件的目录项。

- 删除文件：delete系统调用

  - 需要提供的参数：文件路径、文件名
  - OS做的事情：找到目录文件 - 找到目录项 - 回收磁盘块 - 删除目录项

- 打开文件：open系统调用

  - 需要提供的参数：文件路径、文件名、操作类型（r\rw\a等）

  - OS做的事情：

    - 找到目录文件 - 找到目录项 - 对操作用户鉴权
    - 将目录项复制到内存中的“打开文件列表”中，之后用户进程访问文件就不用每次去查目录了，直接根据“打开文件表”中的该文件编号来找到文件。

  - 打开文件表

    用户进程和系统都有打开文件表：

    <img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202305052300039.png" alt="image-20230505230042808" style="zoom:50%;" />

  - 注意：打开文件open系统调用，并不会把文件数据直接读入内存，而是将文件的目录项复制到打开文件表中，并返回文件标的索引号（也称文件描述符）。

- 关闭文件：close系统调用

  - OS做的事情
    - 将进程打开文件表相应表项删除
    - 回收分配给该文件的内存空间
    - 系统打开文件表，对应表项-1，直到减到0时，才会删除对应表项

- 读文件：read系统调用

  （读之前，需要先打开文件，也就是已经写入了打开文件表中）

  - 需要的参数：指明文件在打开文件表中的索引号，指明读入多少数据，指明读入的数据在内存中的位置
  - OS的操作：会根据读写指针指向的位置找到外存中的数据，将用户指定大小的文件读入到指定的内存区域中。

- 写文件：write系统调用

  编辑文件点击保存后，OS背后完成了write系统调用，将内存中的数据保存到外存

  - 需要的参数：指明文件在打开文件表中的索引号，指明写回外存的数据大小，指明写回外存的数据在内存中的位置
  - OS的操作：将用户指定的内存区域中的指定大小的数据，写回写指针指向的外存区域。

### 文件系统的层次结构

<img src="https://raw.githubusercontent.com/hangx969/upload-images-md/main/202305071808104.png" alt="image-20230507180801810" style="zoom:50%;" />

- 举例说明：删除"D:/xx/xx.xlsx"的后100条记录
  - 用户通过OS提供的接口发出请求 -- 用户接口
  - OS获取到文件路径，一层一层的查找文件目录，找到对应的目录项 -- 文件目录系统
  - 检查用户权限 -- 存取控制模块
  - 鉴权之后，需要把用户提供的记录号转变为逻辑地址 -- 逻辑文件系统、文件信息缓冲区（索引文件）
  - 逻辑地址转换为物理地址 -- 物理文件系统
  - 要对磁盘设备发出删除请求 -- 设备管理程序模块
  - 删除记录后，回收空闲盘块 -- 辅助分配模块
